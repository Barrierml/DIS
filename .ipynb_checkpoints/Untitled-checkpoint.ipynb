{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafba8e2-3945-4d75-92da-af5fd4e9ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from ResUnet import resnet34\n",
    "import time\n",
    "\n",
    "# 定义数据加载类\n",
    "class DepthDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, depth_dir, gt_dir, depth_transform=None, gt_transform=None):\n",
    "        self.depth_dir = depth_dir\n",
    "        self.gt_dir = gt_dir\n",
    "        self.depth_transform = depth_transform\n",
    "        self.gt_transform = gt_transform\n",
    "        self.filenames = os.listdir(depth_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        depth = Image.open(os.path.join(self.depth_dir, self.filenames[idx]))\n",
    "        gt = Image.open(os.path.join(self.gt_dir, self.filenames[idx].replace('.jpg', '.png')))\n",
    "        depth = depth.convert('RGB')\n",
    "        if self.depth_transform:\n",
    "            depth = self.depth_transform(depth)\n",
    "        if self.gt_transform:\n",
    "            gt = self.gt_transform(gt)\n",
    "        return depth, gt\n",
    "\n",
    "\n",
    "# 定义一个计算深度图的损失函数\n",
    "class DepthLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        mse_loss = self.mse_loss(pred, target)\n",
    "        l1_loss = self.l1_loss(pred, target)\n",
    "        return (mse_loss + l1_loss) / 2\n",
    "\n",
    "# 定义一个计算图像分割的损失函数\n",
    "class SegLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        return self.bce_loss(pred, target)\n",
    "\n",
    "# 定义一个计算总损失的函数\n",
    "def total_loss(pred, target, depth_criterion, seg_criterion, depth_weight=0.5):\n",
    "    # print(pred, target)\n",
    "    depth_loss = depth_criterion(pred, target)\n",
    "    seg_loss = seg_criterion(pred, target)\n",
    "    return depth_loss * depth_weight + seg_loss * (1 - depth_weight)\n",
    "\n",
    "# 定义一个计算深度图的准确率的函数\n",
    "def depth_acc(pred, target):\n",
    "    pred = pred.data.cpu().numpy()\n",
    "    target = target.data.cpu().numpy()\n",
    "    pred[pred >= 0.5] = 1\n",
    "    pred[pred < 0.5] = 0\n",
    "    return np.sum(pred == target) / target.size\n",
    "\n",
    "# 定义优化器\n",
    "def get_optimizer(model, lr, weight_decay):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    return optimizer\n",
    "\n",
    "# 定义学习率衰减器\n",
    "def get_lr_scheduler(optimizer, step_size, gamma):\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    return lr_scheduler\n",
    "\n",
    "\n",
    "# 定义训练函数\n",
    "# 深度图处理\n",
    "depth_transform = transforms.Compose([\n",
    "    transforms.Resize((800, 800)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "# 图像分割处理\n",
    "gt_transform = transforms.Compose([\n",
    "    transforms.Resize((800, 800)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "base_dir = '/root/data/'\n",
    "\n",
    "# 定义训练集\n",
    "train_dataset = DepthDataset(depth_dir=base_dir + 'meitu/depth', gt_dir=base_dir + 'meitu/gt', depth_transform=depth_transform, gt_transform=gt_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# 定义验证集\n",
    "val_dataset = DepthDataset(depth_dir=base_dir + 'test/depth', gt_dir=base_dir + 'test/gt', depth_transform=depth_transform, gt_transform=gt_transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443f204-4f53-4ba5-ae56-a01be0a5763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "model = resnet34(3, 1, pretrain=True)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "print('model loaded')\n",
    "\n",
    "# 定义损失函数\n",
    "depth_criterion = DepthLoss()\n",
    "seg_criterion = SegLoss()\n",
    "\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = get_optimizer(model, lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "# 定义学习率衰减器\n",
    "lr_scheduler = get_lr_scheduler(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# 定义训练函数\n",
    "def train(model, train_loader, optimizer, depth_criterion, seg_criterion, epoch):\n",
    "    train_loss = 0\n",
    "    train_depth_acc = 0\n",
    "    start_time = time.time()\n",
    "    for i, (depth, gt) in enumerate(train_loader):\n",
    "        depth = depth.to(device)\n",
    "        gt = gt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(depth)\n",
    "        loss = total_loss(pred, gt, depth_criterion, seg_criterion)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_depth_acc += depth_acc(pred, gt)\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tDepth Acc: {:.6f} \\t Cost time: {:.6f}'.format(\n",
    "                epoch, i * len(depth), len(train_loader.dataset),\n",
    "                100. * i / len(train_loader), loss.item(), depth_acc(pred, gt), time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "    train_loss /= len(train_loader)\n",
    "    train_depth_acc /= len(train_loader)\n",
    "    print('Train Epoch: {}\\tAverage Loss: {:.6f}\\tAverage Depth Acc: {:.6f}'.format(\n",
    "        epoch, train_loss, train_depth_acc))\n",
    "    return train_loss, train_depth_acc\n",
    "\n",
    "# 定义验证函数\n",
    "def val(model, val_loader, depth_criterion, seg_criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_depth_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for depth, gt in val_loader:\n",
    "            depth = depth.to(device)\n",
    "            gt = gt.to(device)\n",
    "            pred = model(depth)\n",
    "            loss = total_loss(pred, gt, depth_criterion, seg_criterion)\n",
    "            val_loss += loss.item()\n",
    "            val_depth_acc += depth_acc(pred, gt)\n",
    "    val_loss /= len(val_loader)\n",
    "    val_depth_acc /= len(val_loader)\n",
    "    print('Val: Average Loss: {:.6f}\\tAverage Depth Acc: {:.6f}'.format(\n",
    "        val_loss, val_depth_acc))\n",
    "    return val_loss, val_depth_acc\n",
    "\n",
    "# 开始训练\n",
    "train_losses = []\n",
    "train_depth_accs = []\n",
    "val_losses = []\n",
    "val_depth_accs = []\n",
    "for epoch in range(1, 21):\n",
    "    train_loss, train_depth_acc = train(model, train_loader, optimizer, depth_criterion, seg_criterion, epoch)\n",
    "    val_loss, val_depth_acc = val(model, val_loader, depth_criterion, seg_criterion)\n",
    "    print('-' * 20)\n",
    "    print('Epoch: {}\\tTrain Loss: {:.6f}\\tTrain Depth Acc: {:.6f}\\tVal Loss: {:.6f}\\tVal Depth Acc: {:.6f}'.format(\n",
    "        epoch, train_loss, train_depth_acc, val_loss, val_depth_acc))\n",
    "    train_losses.append(train_loss)\n",
    "    train_depth_accs.append(train_depth_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_depth_accs.append(val_depth_acc)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
